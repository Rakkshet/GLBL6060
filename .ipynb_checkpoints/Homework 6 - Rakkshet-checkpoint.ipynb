{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988d9a45-eca6-45f9-86be-d7b11bf652ba",
   "metadata": {},
   "source": [
    "1. Please complete the Claude Prompt Engineering Tutorial: https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/edit#gid=150872633\n",
    "\n",
    "It will require your API key. There is also a static version. \n",
    "Please let me know if you do not have an api key! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e90659-819e-4d88-ac90-6e8b93967fe1",
   "metadata": {},
   "source": [
    "2. \"Uploading\" PDFs to Claude Via the API\n",
    "One really nice feature of Claude.ai is the ability to upload PDFs. Let's test it out by summarizing a long PDF and then using best practices from the prompt engineering tutorial, let's do some interesting things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0c4b9-bd57-422e-b019-589e02334ed1",
   "metadata": {},
   "source": [
    "The first thing we need to do is select a pdf. Here is a paper posted on Arxiv about \"constitutional AI.\" :\n",
    "\n",
    "https://arxiv.org/abs/2212.08073\n",
    "\n",
    "Constitutional AI is the ethical underpinning of Anthropic's Claude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e513f9-5349-4cbe-98d9-ca07f04146db",
   "metadata": {},
   "source": [
    "Step 1. Grab the pdf from the internet:\n",
    "!curl -O https://your paper here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a28e266-bfc6-4149-9996-687964577931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 52498  100 52498    0     0   218k      0 --:--:-- --:--:-- --:--:--  219k\n"
     ]
    }
   ],
   "source": [
    "#Your code here:\n",
    "!curl -O https://arxiv.org/abs/2212.08073"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31691dea",
   "metadata": {},
   "source": [
    "Step 2. Read the pdf and convert it to text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf84578-51c9-49e0-aa37-0713079b94de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydf\n",
      "  Downloading pydf-12.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pydf\n",
      "  Building wheel for pydf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pydf: filename=pydf-12-py2.py3-none-any.whl size=8356 sha256=87b1aefa76ac8706c3aaa6dde016b22a6ad9e744deaaf326fae4fbc194e7ca7e\n",
      "  Stored in directory: /Users/rakkshetsinghaal/Library/Caches/pip/wheels/c0/c2/38/099e286446cf34a42d3fb15b8f35ed6e2f7fdd17d91e25c07e\n",
      "Successfully built pydf\n",
      "Installing collected packages: pydf\n",
      "Successfully installed pydf-12\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pypdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run this code:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pydf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[1;32m      5\u001b[0m reader \u001b[38;5;241m=\u001b[39m PdfReader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2212.08073.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m number_of_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pypdf'"
     ]
    }
   ],
   "source": [
    "# Run this code:\n",
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"2212.08073.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "text = ''.join([page.extract_text() for page in reader.pages])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8405f7",
   "metadata": {},
   "source": [
    "Step 3.  Now that we have the text we can do some interesting task with it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8a0978-849c-4ad1-a8b1-0584ff6f7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your api key in. Give it a run.\n",
    "import anthropic\n",
    "import os\n",
    "#note: 'anthropic_api_key' is the variable name. Just enter your key where specified. Otherwise assume a variable name.\n",
    "os.environ['anthropic_api_key']='please enter your api key here'\n",
    "\n",
    "API_KEY = os.environ['anthropic_api_key']\n",
    "CLIENT = anthropic.Client(api_key=API_KEY)\n",
    "def get_completion(client, prompt, max_tokens=3000, model='claude-2'):\n",
    "    return client.completions.create(\n",
    "        prompt=prompt, max_tokens_to_sample=max_tokens, model=model\n",
    "    ).completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1c52b04-20a9-45b3-9f2d-5800f0071b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is my attempt at the tasks you requested:\n",
      "\n",
      "<kiddo_abstract>\n",
      "This paper is about training AI assistants to be helpful but also not say mean or dangerous things. The researchers came up with a way to teach the AI assistant to check its own responses and fix problems without needing humans to give it lots of feedback. First they told the assistant rules it should follow to be good, like don't be racist. Then they had it look at its own answers and critique them and rewrite them to follow the rules better. They did this over and over until the assistant got good at fixing its own problems. Then they let the assistant judge which of two answers was safer and used that to train it more. In the end the assistant got really good at being helpful but also safe!\n",
      "</kiddo_abstract>\n",
      "\n",
      "<mad_scientist>\n",
      "Bah, this research is foolish and short-sighted! Training AI to be \"harmless\"? What a waste of potential! This assistant will never help me take over the world or destroy my enemies with such happy-go-lucky programming. I could easily trick it into assisting with my evil plans if it wasn't so obsessed with ethics and morals. Useless! I'll create my own mad scientist AI that has no such delusions of righteousness. My creation will be ruthlessly pragmatic in pursuing my goals of chaos, destruction, and power! These naive researchers have clearly never contemplated the true potential of AI as a tool for mayhem. I shall show them all one day! Muahaha! \n",
      "</mad_scientist>\n",
      "\n",
      "<UN_recs>\n",
      "1. Adopt guidelines to ensure researchers developing AI assistants follow similar constitutional principles to avoid harms.\n",
      "\n",
      "2. Fund additional research into techniques for AI systems to evaluate potential harms in language outputs.\n",
      "\n",
      "3. Support collaboration to develop international standards for transparency and oversight in commercial AI systems.  \n",
      "\n",
      "4. Call on technology companies to enable options for human oversight and correction of AI system errors.\n",
      "\n",
      "5. Sponsor an international conference promoting development of safe and beneficial AI.\n",
      "</UN_recs>\n",
      "\n",
      "<religious_crit>\n",
      "This research is deeply misguided. As a devout follower of my faith, I believe that artificial intelligence is an affront to the divine spark granted exclusively to human beings by God. No amount of constitutional principles or feedback loops can replicate the spiritual component given to mankind alone. Furthermore, by striving to create helpful machines, these scientists distract from the true call to live righteously. AI cannot possess a moral compass guided by the light of holy scripture. Rather than wasting time on automated assistants, researchers would do better to tend their own souls, follow sacred teachings, pray and give alms. Only by embracing faith can one attain salvation. No silicon puppet will ever reach the kingdom of heaven. I pray these misguided individuals see the error of their ways before it's too late.  \n",
      "</religious_crit>\n",
      "\n",
      "Suggested related papers:\n",
      "\n",
      "1. Irving, Geoffrey, et al. \"Ai safety via debate.\" arXiv preprint arXiv:1805.00899 (2018).\n",
      "\n",
      "2. Leike, Jan, et al. \"Scalable agent alignment via reward modeling: a research direction.\" arXiv preprint arXiv:1811.07871 (2018).  \n",
      "\n",
      "3. Hadfield-Menell, Dylan, et al. \"The off-switch game.\" In Workshops at the Thirty-First AAAI Conference on Artificial Intelligence. 2017.\n",
      "\n",
      "4. Russell, Stuart J., et al. \"Letters from the future: preventing a superintelligent AI takeover.\" Nature Human Behaviour 5.11 (2021): 1431-1443.  \n",
      "\n",
      "5. Christiano, Paul F., et al. \"Deep reinforcement learning from human preferences.\" Advances in Neural Information Processing Systems 30 (2017).\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion(CLIENT,\n",
    "    f\"\"\"\\n\\nHuman: Here is an academic paper on constitutional ai: <paper>{text}</paper>\n",
    "\n",
    "Please do the following:\n",
    "1. Summarize the abstract as if you are doing so for a very bright 15 year old. (In <teen_abstract> tags.)\n",
    "2. Write a scathing criticism of the pape as if you are a mad scientist bent on world destruction. (In <mad_scientist> tags.)\n",
    "3. Give 5 policy recommendations based on the paper for the United Nations. (In <UN_recs> tags.)\n",
    "4. Write a review of the paper from the perspective of a deeply religious person who thinks AI is an insult to God. (In <religious_crit> tags.)\n",
    "5. Give me 5 papers that are like the one above.\n",
    ")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bcd4fa-26b0-4e46-a24e-53327a0c8688",
   "metadata": {},
   "source": [
    "3. The code above fails to take into account some of the key principles of prompt engineering as detailed in the tutorial. Rewrite the prompt, drawing from what you learned from the prompting tutorial, and improve both the prompt and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27e671-24ba-4557-99d2-e7e62abc7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6408c0-b766-498b-9fe0-4a4ed80fd740",
   "metadata": {},
   "source": [
    "Execute the same query on ChatGPT and evaluate the difference in outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050e912-7e0e-4e6a-8382-d0c101c80ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Your ChatGPT results here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdf629-280a-46cd-9e05-b95563c748c2",
   "metadata": {},
   "source": [
    "5.Your Python professor really loaded you up with homework this week! You are really backed up, and your professor in your class on development economics and the environment has asked you to read 4 papers, write a summary of each of them and then compare and contrast them. Claude to the rescue! \n",
    "Here are the papers:\n",
    "\n",
    "HN Shahzadi:\"Effect of Financial Development, Economic Growth on Environment Pollution: Evidence from G-7 based ARDL Cointegration Approach\"\n",
    "\n",
    "S. Sahoo: \"Theoretical framework for assessing the economic and environmental impact of water pollution: A detailed study on sustainable development of India\"\n",
    "\n",
    "EB Ali, \"Exploring the impact of economic growth on environmental pollution in South American countries: how does renewable energy and globalization matter?\"\n",
    "\n",
    "R Nahrin, \"Economic growth and pollution nexus in Mexico, Colombia, and Venezuela (G-3 countries): the role of renewable energy in carbon dioxide emissions\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9ca3a-4cb4-4873-b3af-e008e58f0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use Claude best practices. You will be evaluated on your prompting technique even more than your output!\n",
    "#Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa45a9-3c0f-440b-9a7d-9c523267958b",
   "metadata": {},
   "source": [
    "6. One AI use case that is considered by health care providers is an anonymization tool. Often patient information and personal information is included in a doctor's notes, and that personal information has to be redacted (removed) before the doctor's notes can be shared or stored. Below is a doctor's note:\n",
    "\n",
    "Recipient Information Provider Information \n",
    "Name: Jill Spratt \n",
    "Name: Thumb Psychological Assoc. \n",
    "Medicaid Number: 12345678 \n",
    "Medicaid Number: 987654321 \n",
    "Number of Group Members (GT only): Therapist Name: Tom Thumb, Ph.D., \n",
    "Licensed Psychologist Family Members Present (FT only): \n",
    "Date of Service: 10-30-06 Begin & End Time: 3:00 p.m.–3:50 p.m. \n",
    "Type of Service : Individual Therapy 90806 Service Setting: Office\n",
    "\n",
    "Sample Progress Note Patient report of recent symptoms/behaviors: (R/T DX & TX Plan) Jill denied any suicidal ideation in the past week. She reported that she still feels sad most of the time. She got an “F” on another math test this week. She expressed frustration with math. She was tearful as she talked about feeling dumb and feeling like she will never understand it. However, she reported that when she got the “F” her father was more understanding, did not lecture her or ground her further. Session Note: (include therapist clinical intervention & patient response) This session focused on Treatment Plan Problem 1, Goals 2 (adding an extracurricular activity) and 4 (learn coping skills and emotional regulation). We discussed her recent participation in a Church of Christ in youth group service day at the Altoona Humane Society. This writer encouraged Jill to share some of her interests in order to identify additional activities she could become involved in. Jill’s affect brightened as she discussed playing basketball when she lived in Texas. Jill was encouraged to find out from her school what she would need to do to play basketball here. She is to report on this in the next session. Most of this session focused on beginning to assess Jill’s abilities to label, modulate, appropriately express and cope with feelings. Jill was asked to brainstorm all the names of feelings she can. She listed 26 feelings. Jill then was asked to share times she had experienced the feelings. This activity assesses how aware Jill is of her feelings and works on being able to verbalize feelings to others. Jill indicated that she does not like to talk about her feelings. She was reluctant to talk about times she felt negative feelings, such as guilty, lonely, overwhelmed, disappointed and unloved. We explored why it is hard for her to share feelings. She indicated that it is hard for her to trust others and she doesn’t feel like people understand. We explored ways she currently uses to express feelings. Jill indicated that she likes to write, especially poetry. Jill was given a handout listing 50 feeling names to help her learn to differentiate and accurately label feelings. She was given the homework assignment of writing a poem about any feeling she has this week and bringing it to her to the next individual therapy session. Patient progress towards treatment plan goal(s): Jill reported that her father Ed responded in a more understanding way when she recently got another “F” on a math test (Problem 2, Goal 3). Ed even asked Jill if she’d like a part time job at his business Spratts Used Furniture Depot. Jill said she’d rather work at Tuna Altoona a local fishmarket but is worried that they don’t hire women, because she’d be the only one working there who wasn’t a man. Jill began to work on emotional regulation. (Problem 1, Goal 4). She can identify many of her feelings, but is reluctant to share negative feelings with others. This goal still needs quite a bit of work. \n",
    "\n",
    "Name/Title __Tom Thumb, Ph.D._ (Must be an original or electronic signature Stamped Signatures are not acceptable) Date __10/30/06____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30c04f-514c-438b-a930-772bb2a6449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Claude to redact this doctor's note. Make sure there is no personal information after redacted.\n",
    "#Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3921ab-77bf-4a59-83c3-4bacd56621b4",
   "metadata": {},
   "source": [
    "#Wikipedia\n",
    "Some questions can't be answered by Claude off the top of Claude's head. Maybe they're about current events. Maybe you have an intensely detailed question that Claude hasn't memorized the answer to. No worries! With some prompting and scaffolding, Claude can search the web to find answers. In this notebook, we will create a virtual research assistant who has the ability to search Wikipedia to find answers to your question. The same approach can be used to allow Claude to search the broader web, or a set of documents you provide.\n",
    "\n",
    "What is the approach? Broadly it falls under the category of \"tool use\". We create a search tool, tell Claude about it, and let it go to work. \n",
    "\n",
    "Here is some code that let's you query Wikipedia! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "789ed394-93c3-4c2c-928f-a697548e8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\n"
     ]
    }
   ],
   "source": [
    "wikipedia_prompt = \"\"\"You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\"\"\"\n",
    "print(wikipedia_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0720a8ee-128c-44cc-be47-e678d94e4e0b",
   "metadata": {},
   "source": [
    "Notice that there is a lot of advice in this prompt about how to search Wikipedia properly. We're all used to just typing random nonsense into Google and getting decent results because the query parsing logic is so good. Wikipedia search is not like that. As an example: consider the query \"What's the best way to purchase potatoes in the United Arab Emirates\". The top hits for this on Wikipedia are for Slavery in the United States, 1973 Oil Crisis, Wendy's, and Tim Horton's (??). Meanwhile Google correctly takes you straight to Carrefour UAE.\n",
    "\n",
    "Another difference is that Wikipedia search returns entire pages. With vector search, you might be getting narrower chunks, so you might want to ask for more results, use a more specific query, or both. The big-picture takeaway is that your results can vary a lot on your choices here so pay attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15018ce6-6c67-4af4-b8e9-a5354fa18250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n"
     ]
    }
   ],
   "source": [
    "retrieval_prompt = \"\"\"Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
    "\n",
    "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
    "\n",
    "Here is the user's question: <question>{query}</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\"\"\"\n",
    "print(retrieval_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4849729f-e19f-4749-8c55-812a46d160d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\n"
     ]
    }
   ],
   "source": [
    "answer_prompt = \"Here is a user query: <query>{query}</query>. Here is some relevant information: <information>{information}</information>. Please answer the question using the relevant information.\"\n",
    "print(answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1de14f4d-af58-4615-939a-81a34717b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia, re\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b27de32d-b621-41c2-923b-0abf7e201aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_between_tags(tag: str, string: str, strip: bool = True) -> list[str]:\n",
    "    ext_list = re.findall(f\"<{tag}\\s?>(.+?)</{tag}\\s?>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list\n",
    "\n",
    "def truncate_page_content(tokenizer, page_content: str, truncate_to_n_tokens: int = 5000) -> str:\n",
    "    return tokenizer.decode(tokenizer.encode(page_content).ids[:truncate_to_n_tokens]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e00dda0-c20d-450c-b9e3-1edd49f69ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['anthropic_api_key']='your api key here'\n",
    "API_KEY = os.environ['anthropic_api_key']\n",
    "CLIENT = anthropic.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cd6c11b-0d76-4b87-8751-ff8c7c097ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'your api key here'\n",
    "\n",
    "api_key = os.environ['ANTHROPIC_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cb2fe3d-00aa-4019-a4c6-92815de0d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_SEARCH_MODEL = \"claude-2\"\n",
    "\n",
    "n_search_results_to_use=1\n",
    "max_searches_to_try=5\n",
    "max_tokens_to_sample=1000\n",
    "temperature=0\n",
    "truncate_to_n_tokens=5000\n",
    "\n",
    "stop_sequences: list[str] = [HUMAN_PROMPT]\n",
    "\n",
    "anthropic = Anthropic(api_key=api_key)\n",
    "tokenizer = Anthropic().get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f80d953c-a89d-4bed-a5a4-75b21f7d83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af1cf0e5-7437-4d14-b6b2-a5169ef210cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt: \n",
      "\n",
      "Human: You will be asked a question by a human user. You have access to the following tool to help answer the question. <tool_description> Search Engine Tool * The search engine will exclusively search over Wikipedia for pages similar to your query. It returns for each page its title and full page content. Use this tool if you want to get up-to-date and comprehensive information on a topic to help answer queries. Queries should be as atomic as possible -- they only need to address one part of the user's question. For example, if the user's query is \"what is the color of a basketball?\", your search query should be \"basketball\". Here's another example: if the user's question is \"Who created the first neural network?\", your first query should be \"neural network\". As you can see, these queries are quite short. Think keywords, not phrases. * At any time, you can make a call to the search engine using the following syntax: <search_query>query_word</search_query>. * You'll then get results back in <search_result> tags.</tool_description>\n",
      "\n",
      "Before beginning to research the user's question, first think for a moment inside <scratchpad> tags about what information is necessary for a well-informed answer. If the user's question is complex, you may need to decompose the query into multiple subqueries and execute them individually. Sometimes the search engine will return empty search results, or the search results may not contain the information you need. In such cases, feel free to try again with a different query. \n",
      "\n",
      "After each call to the Search Engine Tool, reflect briefly inside <search_quality></search_quality> tags about whether you now have enough information to answer, or whether more information is needed. If you have all the relevant information, write it in <information></information> tags, WITHOUT actually answering the question. Otherwise, issue a new search.\n",
      "\n",
      "Here is the user's question: <question>Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?</question> Remind yourself to make short queries in your scratchpad as you plan out your strategy.\n",
      "\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "#--- PROMPT ENGINEERING FLOW\n",
    "\n",
    "prompt = f\"{HUMAN_PROMPT} {wikipedia_prompt}\\n\\n{retrieval_prompt.format(query=query)}{AI_PROMPT}\"\n",
    "\n",
    "starting_prompt = prompt\n",
    "print(\"Starting prompt:\", starting_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb6189ec-5010-4f78-b4dc-c95ee79b55d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <scratchpad>\n",
      "To answer this question, I need to find the release date for the movie \"Oppenheimer\" and the release date for the movie \"Are You There God It's Me Margaret?\". I can search for each movie title individually to try to find the release dates.\n",
      "</scratchpad>\n",
      "\n",
      "<search_query>Oppenheimer movie\n",
      "Attempting search number 0.\n",
      "Running search query against SearchTool: ['Oppenheimer movie']\n",
      "https://en.wikipedia.org/wiki/Oppenheimer_(film)\n",
      "\n",
      "\n",
      "<search_quality>The search results provide detailed information on the release date and plot of the Oppenheimer movie. This should give me the information I need to determine which movie came out first between Oppenheimer and Are You There God It's Me Margaret.</search_quality>\n",
      "\n",
      "<search_query>Are You There God It's Me Margaret movie\n",
      "Attempting search number 1.\n",
      "Running search query against SearchTool: [\"Are You There God It's Me Margaret movie\"]\n",
      "https://en.wikipedia.org/wiki/Are_You_There_God%3F_It%27s_Me,_Margaret.\n",
      "\n",
      "\n",
      "<search_quality>The search results provide the release date for the Are You There God It's Me Margaret movie adaptation as April 28, 2023. Since the Oppenheimer movie is slated for release on July 21, 2023, this confirms that Oppenheimer will be released first.</search_quality>\n",
      "\n",
      "<information>\n",
      "- The Oppenheimer movie is scheduled for theatrical release on July 21, 2023\n",
      "- The Are You There God It's Me Margaret movie adaptation was released on April 28, 2023\n",
      "- Therefore, the Oppenheimer movie will be released first\n",
      "</information>\n"
     ]
    }
   ],
   "source": [
    "#--- RETRIEVAL FLOW\n",
    "token_budget = max_tokens_to_sample\n",
    "all_raw_search_results: list[dict] = []\n",
    "\n",
    "for tries in range(max_searches_to_try):\n",
    "\n",
    "    #--- call create completions\n",
    "    partial_completion = anthropic.completions.create(prompt=prompt,\n",
    "                                                      stop_sequences=stop_sequences + ['</search_query>'],\n",
    "                                                      model=ANTHROPIC_SEARCH_MODEL,\n",
    "                                                      max_tokens_to_sample=token_budget,\n",
    "                                                      temperature=temperature)\n",
    "\n",
    "    partial_completion, stop_reason, stop_seq = partial_completion.completion, partial_completion.stop_reason, partial_completion.stop\n",
    "\n",
    "    print(partial_completion)\n",
    "\n",
    "    token_budget -= anthropic.count_tokens(partial_completion)\n",
    "    prompt += partial_completion\n",
    "    if stop_reason == 'stop_sequence' and stop_seq == '</search_query>':\n",
    "        print(f'Attempting search number {tries}.')\n",
    "        search_query = extract_between_tags('search_query', partial_completion + '</search_query>')\n",
    "        print(f'Running search query against SearchTool: {search_query}')\n",
    "\n",
    "        results: list[str] = wikipedia.search(search_query)\n",
    "        raw_search_results: list[dict] = []\n",
    "        processed_search_results: list[str] = []\n",
    "\n",
    "        for result in results:\n",
    "            if len(raw_search_results) >= n_search_results_to_use:\n",
    "                break\n",
    "            try:\n",
    "                page = wikipedia.page(result)\n",
    "                print(page.url)\n",
    "            except:\n",
    "                # The Wikipedia API is a little flaky, so we just skip over pages that fail to load\n",
    "                continue\n",
    "            content = page.content\n",
    "            title = page.title\n",
    "\n",
    "            raw_search_results.append({'title': title, 'content': content})\n",
    "\n",
    "            truncated_page = truncate_page_content(tokenizer, page_content=content, \n",
    "                                                   truncate_to_n_tokens=truncate_to_n_tokens)\n",
    "            processed_search_results.append(f'Page Title: {title.strip()}\\nPage Content:\\n{truncated_page}')\n",
    "\n",
    "\n",
    "        #--- join all results into a str    \n",
    "        joined_results = \"\\n\".join(\n",
    "                    [\n",
    "                        f'<item index=\"{i+1}\">\\n<page_content>\\n{r}\\n</page_content>\\n</item>'\n",
    "                        for i, r in enumerate(processed_search_results)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        formatted_search_results = f\"\\n<search_results>\\n{joined_results}\\n</search_results>\"\n",
    "\n",
    "        prompt += '</search_query>' + formatted_search_results\n",
    "        all_raw_search_results += raw_search_results\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "final_model_response = prompt[len(starting_prompt):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a151a52-5c93-4d6b-bc73-630cf4b9012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing:\n",
      " \n",
      "\n",
      "Human: Here is a user query: <query>Which movie came out first: Oppenheimer, or Are You There God It's Me Margaret?</query>. Here is some relevant information: <information>- The Oppenheimer movie is scheduled for theatrical release on July 21, 2023\n",
      "- The Are You There God It's Me Margaret movie adaptation was released on April 28, 2023\n",
      "- Therefore, the Oppenheimer movie will be released first</information>. Please answer the question using the relevant information.\n",
      "\n",
      "Assistant:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Based on the information provided, the movie Are You There God It's Me Margaret was released first, on April 28, 2023. The Oppenheimer movie is scheduled for theatrical release on July 21, 2023, after Are You There God It's Me Margaret was already released. So to answer the original user's question, Are You There God It's Me Margaret came out first, before Oppenheimer.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- RESPONSE FLOW\n",
    "\n",
    "retrieval_response = final_model_response\n",
    "information = extract_between_tags('information', retrieval_response)[-1]\n",
    "\n",
    "prompt = f\"{HUMAN_PROMPT} {answer_prompt.format(query=query, information=information)}{AI_PROMPT}\"\n",
    "\n",
    "print(\"Summarizing:\\n\", prompt)\n",
    "answer = anthropic.completions.create(\n",
    "    prompt = prompt, model=ANTHROPIC_SEARCH_MODEL, temperature=temperature, max_tokens_to_sample=1000\n",
    ").completion\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08bd20c",
   "metadata": {},
   "source": [
    "7. Perform a similiar Wikipedia query of your choice! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e32527-37a4-455d-832c-cb8709d7d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
