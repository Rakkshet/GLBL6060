{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ6eW22LJM_n"
   },
   "source": [
    "# HW 7:\n",
    "This homework we are going to start with a dataset ingest, some cleaning and some visualizations. Then move to Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPXtYV6tLA7v"
   },
   "source": [
    "## US Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHx4uFrkJQTE"
   },
   "source": [
    "Load the data posted on the github repo \"us-population-2010-2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a lambda function, add a column to the dataframe that provides standard two letter abbreviations to all of the US States. For example, Connecticut would be CT.\n",
    "https://www.50states.com/abbreviations.htm\n",
    "*hint* there is a python package called \"us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape your data, and create a new df called df_reshaped so that:\n",
    "\n",
    "1. Convert 'year' column values to integers\n",
    "2. Convert 'states' to strings\n",
    "3. Get rid of the commas in the population numbers, and convert them to integers\n",
    "4. Check your df_reshaped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Save your df_reshaped to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset your dataframe by selected_year = 2019 year create a new dataframe called df_selected_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort df_selected_year by population, from highest to lowest, and create a new df called \"df_selected_year_sorted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JM8sxDepnwMG",
    "outputId": "f123e0f1-b1a2-4a41-b4c0-420b70fe5a53"
   },
   "outputs": [],
   "source": [
    "# Here is a function to calculate population difference between selected and previous year\n",
    "def calculate_population_difference(input_df, input_year):\n",
    "  selected_year_data = input_df[input_df['year'] == input_year].reset_index()\n",
    "  previous_year_data = input_df[input_df['year'] == input_year - 1].reset_index()\n",
    "  selected_year_data['population_difference'] = selected_year_data.population.sub(previous_year_data.population, fill_value=0)\n",
    "  selected_year_data['population_difference_absolute'] = abs(selected_year_data['population_difference'])\n",
    "  return pd.concat([selected_year_data.states, selected_year_data.id, selected_year_data.population, selected_year_data.population_difference, selected_year_data.population_difference_absolute], axis=1).sort_values(by=\"population_difference\", ascending=False)\n",
    "\n",
    "df_population_difference_sorted = calculate_population_difference(df_reshaped, selected_year)\n",
    "df_population_difference_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "kjtiLBxV6cNq",
    "outputId": "3989fa48-8d64-4114-d3cd-63c07daf4127"
   },
   "outputs": [],
   "source": [
    "# Filter states with population difference > 50000\n",
    "df_greater_50000 = #Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "085JORge7E2N",
    "outputId": "ec84f197-5224-42f4-97f2-e880fab8219e"
   },
   "outputs": [],
   "source": [
    "# Calculate the % of States with population difference > 50000\n",
    "#Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnY0jA7irX1Z"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRrwBt3skrp1"
   },
   "source": [
    "### Heatmap: run the following code to see a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "Vf8v9OjMku8M",
    "outputId": "901a9b29-439c-4fe3-9a53-0a52ad366a94"
   },
   "outputs": [],
   "source": [
    "!pip install altair\n",
    "import altair as alt\n",
    "\n",
    "alt.themes.enable(\"dark\")\n",
    "\n",
    "heatmap = alt.Chart(df_reshaped).mark_rect().encode(\n",
    "        y=alt.Y('year:O', axis=alt.Axis(title=\"Year\", titleFontSize=16, titlePadding=15, titleFontWeight=900, labelAngle=0)),\n",
    "        x=alt.X('states:O', axis=alt.Axis(title=\"States\", titleFontSize=16, titlePadding=15, titleFontWeight=900)),\n",
    "        color=alt.Color('max(population):Q',\n",
    "                         legend=alt.Legend(title=\" \"),\n",
    "                         scale=alt.Scale(scheme=\"blueorange\")),\n",
    "        stroke=alt.value('black'),\n",
    "        strokeWidth=alt.value(0.25),\n",
    "        #tooltip=[\n",
    "        #    alt.Tooltip('year:O', title='Year'),\n",
    "        #    alt.Tooltip('population:Q', title='Population')\n",
    "        #]\n",
    "    ).properties(width=900\n",
    "    #).configure_legend(orient='bottom', titleFontSize=16, labelFontSize=14, titlePadding=0\n",
    "    #).configure_axisX(labelFontSize=14)\n",
    "    ).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12\n",
    "    )\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69oYy6edR4V7"
   },
   "source": [
    "### Choropleth: Run the following code to get a map of the population for the selected year above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "rCT-THXqdc2e",
    "outputId": "ef2d0b90-45d8-496c-8176-96fba73623b6"
   },
   "outputs": [],
   "source": [
    "# Choropleth via Altair\n",
    "!pip install vega_datasets\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "alt.themes.enable(\"dark\")\n",
    "\n",
    "states = alt.topo_feature(data.us_10m.url, 'states')\n",
    "\n",
    "alt.Chart(states).mark_geoshape().encode(\n",
    "    color=alt.Color('population:Q', scale=alt.Scale(scheme='blues')),   # scale=color_scale\n",
    "    stroke=alt.value('#154360')\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(df_selected_year, 'id', list(df_selected_year.columns))\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ").project(\n",
    "    type='albersUsa'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pycharm:\n",
    "Create a pdf reader streamlit app in pycharm using the following code.Upload some pdfs and perform some queries. \n",
    "Below capture 5 queries and 5 responses. Check to make sure the responses are accurate. See if you can get your app to fail. Analyze why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "\n",
    "    text: str = ''\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "           text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks= text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI()\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain\n",
    "\n",
    "def handle_userinput(user_question):\n",
    "    response = st.session_state.conversation({'question':user_question})\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "    for i, message in enumerate(st.session_state.chat_history):\n",
    "        if i%2 ==0:\n",
    "            st.write(f'Human Question: {message.content}')\n",
    "        else:\n",
    "            st.write(f'AI Response: {message.content}')\n",
    "\n",
    "        \n",
    "def main():\n",
    "    load_dotenv()\n",
    "    st.set_page_config(page_title=\"Chat with PDFs\", page_icon=\":scalpel:\")\n",
    "\n",
    "    if \"conversation\" not in st.session_state:\n",
    "        st.session_state.conversation = None\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history= None\n",
    "\n",
    "    st.header(\"Chat with PDFs :medical_symbol:\")\n",
    "    user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "    if user_question:\n",
    "        handle_userinput(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.subheader(\"Your documents\")\n",
    "        pdf_docs = st.file_uploader(\"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n",
    "        if st.button('Process'):\n",
    "            with st.spinner(\"Processing...\"):\n",
    "\n",
    "            #get pdf texts\n",
    "                raw_text = get_pdf_text(pdf_docs)\n",
    "                #st.write(raw_text)\n",
    "\n",
    "            #chunk pdfs\n",
    "                text_chunks = get_text_chunks(raw_text)\n",
    "                #st.write(text_chunks)\n",
    "\n",
    "            #create vector store with embeddings\n",
    "                vectorstore = get_vectorstore(text_chunks)\n",
    "\n",
    "            # create conversation chain\n",
    "                st.session_state.conversation = get_conversation_chain(vectorstore)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Your analysis here:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
